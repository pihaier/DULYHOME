"""
HS ì½”ë“œ CSV ë°ì´í„°ë¥¼ Supabaseì— ì—…ë¡œë“œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
import pandas as pd
import os
from supabase import create_client, Client
from dotenv import load_dotenv
import time

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
env_path = r"C:\Users\bishi\Desktop\ğŸ’»_ê°œë°œ_í”„ë¡œê·¸ë¨\ê°œë°œìë£Œ\erp-custom\nextjs_flexy\.env.local"
load_dotenv(env_path)

# Supabase í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
url = os.getenv("NEXT_PUBLIC_SUPABASE_URL")
key = os.getenv("SUPABASE_SERVICE_ROLE_KEY") or os.getenv("NEXT_PUBLIC_SUPABASE_ANON_KEY")

if not url or not key:
    print("âŒ í™˜ê²½ë³€ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print(f"   .env.local ê²½ë¡œ: {env_path}")
    print(f"   URL: {url}")
    print(f"   KEY: {'ìˆìŒ' if key else 'ì—†ìŒ'}")
    exit(1)
supabase: Client = create_client(url, key)

# ë°ì´í„° ë””ë ‰í† ë¦¬
data_dir = r"C:\Users\bishi\Desktop\ğŸ’»_ê°œë°œ_í”„ë¡œê·¸ë¨\ê°œë°œìë£Œ\erp-custom\data\hs_codes"

def upload_hs_codes():
    """CSV íŒŒì¼ë“¤ì„ Supabaseì— ì—…ë¡œë“œ"""
    
    # í†µí•© íŒŒì¼ ì½ê¸°
    all_codes_path = os.path.join(data_dir, 'hs_codes_all.csv')
    
    if not os.path.exists(all_codes_path):
        print("âŒ í†µí•© íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. convert_hs_excel_to_csv.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return False
    
    # CSV ì½ê¸°
    df = pd.read_csv(all_codes_path)
    
    print(f"ì´ {len(df)} ê°œì˜ HS ì½”ë“œë¥¼ ì—…ë¡œë“œí•©ë‹ˆë‹¤...")
    print(f"ë ˆë²¨ë³„ ë¶„í¬:")
    print(df['level'].value_counts().sort_index())
    
    # NaN ê°’ì„ Noneìœ¼ë¡œ ë³€í™˜
    df = df.where(pd.notnull(df), None)
    
    # ë°°ì¹˜ ì²˜ë¦¬ (100ê°œì”©)
    batch_size = 100
    total_uploaded = 0
    
    for i in range(0, len(df), batch_size):
        batch = df.iloc[i:i+batch_size]
        
        # ë°ì´í„° ì¤€ë¹„
        records = []
        for _, row in batch.iterrows():
            record = {
                'hs_code': str(row['hs_code']),
                'level': int(row['level']),
                'parent_code': str(row['parent_code']) if row['parent_code'] else None,
                'name_ko': row['name_ko'],
                'name_en': row.get('name_en'),
                'description': None,
                'common_aliases': [],
                'search_keywords': []
            }
            records.append(record)
        
        try:
            # Supabaseì— ì‚½ì…
            result = supabase.table('hs_codes_hierarchy').upsert(
                records,
                on_conflict='hs_code'
            ).execute()
            
            total_uploaded += len(records)
            print(f"âœ… {total_uploaded}/{len(df)} ì—…ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ {i//batch_size + 1} ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False
        
        # API ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
        time.sleep(0.1)
    
    print(f"\nâœ… ì´ {total_uploaded} ê°œì˜ HS ì½”ë“œ ì—…ë¡œë“œ ì™„ë£Œ!")
    return True

def add_common_aliases():
    """ìì£¼ ì‚¬ìš©ë˜ëŠ” ë³„ì¹­ ì¶”ê°€"""
    
    print("\n=== ì¼ë°˜ì ì¸ ë³„ì¹­ ì¶”ê°€ ===")
    
    # ë³„ì¹­ ë§¤í•‘ (ì˜ˆì‹œ)
    aliases = [
        {'hs_code': '8471301000', 'aliases': ['ë…¸íŠ¸ë¶', 'ë©í†±', 'ë…¸íŠ¸ë¶ì»´í“¨í„°', 'laptop'], 'keywords': ['íœ´ëŒ€ìš©', 'ì»´í“¨í„°', 'ë…¸íŠ¸ë¶PC']},
        {'hs_code': '8517121020', 'aliases': ['ìŠ¤ë§ˆíŠ¸í°', 'íœ´ëŒ€í°', 'í•¸ë“œí°', 'ëª¨ë°”ì¼í°'], 'keywords': ['ì „í™”ê¸°', 'íœ´ëŒ€ì „í™”', 'ì´ë™ì „í™”']},
        {'hs_code': '8528722000', 'aliases': ['TV', 'í‹°ë¹„', 'í…”ë ˆë¹„ì „', 'í…”ë ˆë¹„ì ¼'], 'keywords': ['í…”ë ˆë¹„ì „', 'ìˆ˜ìƒê¸°', 'ëª¨ë‹ˆí„°']},
        {'hs_code': '6110301000', 'aliases': ['ìŠ¤ì›¨í„°', 'ìŠ¤ì›¨íƒ€', 'í’€ì˜¤ë²„'], 'keywords': ['ë‹ˆíŠ¸', 'ë©”ë¦¬ì•¼ìŠ¤', 'í¸ë¬¼']},
        {'hs_code': '6404191000', 'aliases': ['ìš´ë™í™”', 'ìŠ¤ë‹ˆì»¤ì¦ˆ', 'ëŸ°ë‹í™”'], 'keywords': ['ì‹ ë°œ', 'ìŠ¤í¬ì¸ í™”', 'ìš´ë™ìš©']},
        {'hs_code': '9503001100', 'aliases': ['ì¸í˜•', 'ë´‰ì œì¸í˜•', 'í”ŒëŸ¬ì‹œí† ì´'], 'keywords': ['ì¥ë‚œê°', 'ì™„êµ¬', 'ì–´ë¦°ì´']},
        {'hs_code': '8471494000', 'aliases': ['ë°ìŠ¤í¬í†±', 'ë°ìŠ¤í¬íƒ‘', 'PC'], 'keywords': ['ì»´í“¨í„°', 'ê°œì¸ìš©ì»´í“¨í„°', 'ë³¸ì²´']},
        {'hs_code': '8471604020', 'aliases': ['í‚¤ë³´ë“œ'], 'keywords': ['ì…ë ¥ì¥ì¹˜', 'ìíŒ', 'ì»´í“¨í„°í‚¤ë³´ë“œ']},
        {'hs_code': '8471607000', 'aliases': ['ë§ˆìš°ìŠ¤'], 'keywords': ['ì…ë ¥ì¥ì¹˜', 'í¬ì¸íŒ…ì¥ì¹˜', 'ì»´í“¨í„°ë§ˆìš°ìŠ¤']},
    ]
    
    for item in aliases:
        try:
            # ë³„ì¹­ê³¼ í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸
            result = supabase.table('hs_codes_hierarchy').update({
                'common_aliases': item['aliases'],
                'search_keywords': item['keywords']
            }).eq('hs_code', item['hs_code']).execute()
            
            if result.data:
                print(f"âœ… {item['hs_code']}: ë³„ì¹­ {len(item['aliases'])}ê°œ, í‚¤ì›Œë“œ {len(item['keywords'])}ê°œ ì¶”ê°€")
            else:
                print(f"âš ï¸ {item['hs_code']}: HS ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                
        except Exception as e:
            print(f"âŒ {item['hs_code']}: ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ - {str(e)}")
    
    print("\nâœ… ë³„ì¹­ ì¶”ê°€ ì™„ë£Œ!")

def verify_upload():
    """ì—…ë¡œë“œ ê²€ì¦"""
    
    print("\n=== ì—…ë¡œë“œ ê²€ì¦ ===")
    
    # ê° ë ˆë²¨ë³„ ê°œìˆ˜ í™•ì¸
    for level in [2, 4, 6, 10]:
        result = supabase.table('hs_codes_hierarchy').select('count', count='exact').eq('level', level).execute()
        print(f"Level {level}: {result.count} items")
    
    # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
    print("\nìƒ˜í”Œ ë°ì´í„°:")
    result = supabase.table('hs_codes_hierarchy').select('*').limit(5).execute()
    for item in result.data:
        print(f"  {item['hs_code']} (L{item['level']}): {item['name_ko'][:30]}...")

if __name__ == "__main__":
    print("=== HS ì½”ë“œ Supabase ì—…ë¡œë“œ ì‹œì‘ ===\n")
    
    # 1. HS ì½”ë“œ ì—…ë¡œë“œ
    if upload_hs_codes():
        
        # 2. ë³„ì¹­ ì¶”ê°€
        add_common_aliases()
        
        # 3. ì—…ë¡œë“œ ê²€ì¦
        verify_upload()
    else:
        print("\nâŒ ì—…ë¡œë“œ ì‹¤íŒ¨")